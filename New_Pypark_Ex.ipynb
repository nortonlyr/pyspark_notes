{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_json = 'people.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(people_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'name']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+\n",
      "|summary|               age|   name|\n",
      "+-------+------------------+-------+\n",
      "|  count|                 2|      3|\n",
      "|   mean|              24.5|   null|\n",
      "| stddev|7.7781745930520225|   null|\n",
      "|    min|                19|   Andy|\n",
      "|    max|                30|Michael|\n",
      "+-------+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.types import Row\n",
    "from datetime import datetime\n",
    "from pyspark import SparkContext as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.context.SparkContext"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parallelize() missing 1 required positional argument: 'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-62c6b3084de4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minside\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: parallelize() missing 1 required positional argument: 'c'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "num_samples = 100000000\n",
    "\n",
    "def inside(p):     \n",
    "    x, y = random.random(), random.random()\n",
    "    return x*x + y*y < 1\n",
    "\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "\n",
    "pi = 4 * count / num_samples\n",
    "print(pi)\n",
    "\n",
    "sc.stop()\n",
    "# parallelize() missing 1 required positional argument: 'c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parallelize() missing 1 required positional argument: 'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5e2c90fb3463>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msimple_ex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"alice\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msimple_ex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: parallelize() missing 1 required positional argument: 'c'"
     ]
    }
   ],
   "source": [
    "simple_ex = sc.parallelize([1, \"alice\", 50])\n",
    "simple_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StringType, IntegerType, StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = [StructField('age', IntegerType(), True),\n",
    "              StructField('name', StringType(), True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_struct = StructType(fields=data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(people_json, schema=final_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['age', 'name']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, name: string, double: int]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn('double', df['age']*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|my_new_age|   name|\n",
      "+----------+-------+\n",
      "|      null|Michael|\n",
      "|        30|   Andy|\n",
      "|        19| Justin|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed('age', 'my_new_age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SQL in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = spark.sql('SELECT * FROM people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = spark.sql(\"SELECT * FROM people WHERE age = 30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|age|name|\n",
      "+---+----+\n",
      "| 30|Andy|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('ops').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_stock = 'msft.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(msft_stock, header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|      Date|      Open|      High|       Low|     Close| Adj Close|  Volume|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|2020-02-03|170.429993|     174.5|170.399994|174.380005|172.552048|30149100|\n",
      "|2020-02-04|177.139999|180.639999|176.309998|180.119995|178.231873|36433300|\n",
      "|2020-02-05|184.029999|184.199997|178.410004|179.899994|178.014191|39186300|\n",
      "|2020-02-06|180.970001|183.820007|180.059998|183.630005|181.705093|27751400|\n",
      "|2020-02-07|182.850006|185.630005|182.479996|183.889999|181.962357|33529100|\n",
      "|2020-02-10|183.580002|188.839996|    183.25|188.699997|186.721939|35844300|\n",
      "|2020-02-11|190.649994|190.699997|     183.5|184.440002|182.506607|53159900|\n",
      "|2020-02-12|185.580002|185.850006|181.850006|184.710007|182.773773|47062900|\n",
      "|2020-02-13|183.080002|186.229996|182.869995|183.710007|181.784271|35295800|\n",
      "|2020-02-14|    183.25|185.410004|182.649994|185.350006|183.407059|23149500|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|      Date|      Open|      High|       Low|     Close| Adj Close|  Volume|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|2020-02-03|170.429993|     174.5|170.399994|174.380005|172.552048|30149100|\n",
      "|2020-02-24|167.770004|174.550003|163.229996|170.889999|169.560516|68311100|\n",
      "|2020-02-25|174.199997|174.839996|167.649994|168.070007|166.762451|68073300|\n",
      "|2020-02-26|169.710007|173.259995|168.210007|170.169998|  168.8461|56206100|\n",
      "|2020-02-27|163.320007|167.029999|157.979996|158.179993|156.949387|93174900|\n",
      "|2020-02-28|152.410004|163.710007|     152.0|162.009995|160.749588|97073600|\n",
      "|2020-03-02|165.309998|172.919998|162.309998|172.789993|171.445724|71030800|\n",
      "|2020-03-03|173.800003|     175.0|162.259995|164.509995|163.230148|71677000|\n",
      "|2020-03-04|168.490005|170.699997|165.619995|170.550003|169.223145|49814400|\n",
      "|2020-03-05|166.050003|170.869995|165.690002|166.270004| 164.97644|47817300|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('Close < 175').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      Open|\n",
      "+----------+\n",
      "|170.429993|\n",
      "|167.770004|\n",
      "|174.199997|\n",
      "|169.710007|\n",
      "|163.320007|\n",
      "|152.410004|\n",
      "|165.309998|\n",
      "|173.800003|\n",
      "|168.490005|\n",
      "|166.050003|\n",
      "+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('Close < 175').select('Open').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|      Date|      Open|      High|       Low|     Close| Adj Close|  Volume|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|2020-02-04|177.139999|180.639999|176.309998|180.119995|178.231873|36433300|\n",
      "|2020-02-05|184.029999|184.199997|178.410004|179.899994|178.014191|39186300|\n",
      "|2020-02-06|180.970001|183.820007|180.059998|183.630005|181.705093|27751400|\n",
      "|2020-02-07|182.850006|185.630005|182.479996|183.889999|181.962357|33529100|\n",
      "|2020-02-10|183.580002|188.839996|    183.25|188.699997|186.721939|35844300|\n",
      "|2020-02-11|190.649994|190.699997|     183.5|184.440002|182.506607|53159900|\n",
      "|2020-02-12|185.580002|185.850006|181.850006|184.710007|182.773773|47062900|\n",
      "|2020-02-13|183.080002|186.229996|182.869995|183.710007|181.784271|35295800|\n",
      "|2020-02-14|    183.25|185.410004|182.649994|185.350006|183.407059|23149500|\n",
      "|2020-02-18|185.610001|187.699997|     185.5|187.229996|185.267365|27792200|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Close'] > 175).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|  Volume|\n",
      "+--------+\n",
      "|36433300|\n",
      "|39186300|\n",
      "|27751400|\n",
      "|33529100|\n",
      "|35844300|\n",
      "|53159900|\n",
      "|47062900|\n",
      "|35295800|\n",
      "|23149500|\n",
      "|27792200|\n",
      "+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Close'] > 175).select('Volume').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|      Date|      Open|      High|       Low|     Close| Adj Close|  Volume|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|2020-04-16|174.300003|177.279999|172.899994|177.039993|175.662643|50479600|\n",
      "|2020-04-29|173.220001|177.679993|171.880005|177.429993|176.049622|51286600|\n",
      "|2020-05-04|174.490005|     179.0|173.800003|178.839996|177.448639|30372900|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df['Close'] > 175) & (df['Open'] < 175)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|  Volume|\n",
      "+--------+\n",
      "|36433300|\n",
      "|39186300|\n",
      "|27751400|\n",
      "|33529100|\n",
      "|35844300|\n",
      "|53159900|\n",
      "|47062900|\n",
      "|35295800|\n",
      "|23149500|\n",
      "|27792200|\n",
      "+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Close'] > 175).select('Volume').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|      Date|      Open|      High|       Low|     Close| Adj Close|  Volume|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|2020-04-27|176.589996|176.899994|173.300003|174.050003|172.695923|33194400|\n",
      "|2020-04-28|175.589996|175.669998|169.389999|169.809998|168.488922|34392700|\n",
      "|2020-05-01|175.800003|178.639999|174.009995|174.570007|173.211899|39370500|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df['Close'] < 175) & (df['Open'] > 175)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|      Date|      Open|      High|       Low|     Close| Adj Close|  Volume|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|2020-02-03|170.429993|     174.5|170.399994|174.380005|172.552048|30149100|\n",
      "|2020-02-04|177.139999|180.639999|176.309998|180.119995|178.231873|36433300|\n",
      "|2020-02-05|184.029999|184.199997|178.410004|179.899994|178.014191|39186300|\n",
      "|2020-02-06|180.970001|183.820007|180.059998|183.630005|181.705093|27751400|\n",
      "|2020-02-07|182.850006|185.630005|182.479996|183.889999|181.962357|33529100|\n",
      "|2020-02-10|183.580002|188.839996|    183.25|188.699997|186.721939|35844300|\n",
      "|2020-02-11|190.649994|190.699997|     183.5|184.440002|182.506607|53159900|\n",
      "|2020-02-12|185.580002|185.850006|181.850006|184.710007|182.773773|47062900|\n",
      "|2020-02-13|183.080002|186.229996|182.869995|183.710007|181.784271|35295800|\n",
      "|2020-02-14|    183.25|185.410004|182.649994|185.350006|183.407059|23149500|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df['Close'] < 200) & ~(df['Open'] > 200)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|      Date|      Open|      High|       Low|     Close| Adj Close|  Volume|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "|2020-02-12|185.580002|185.850006|181.850006|184.710007|182.773773|47062900|\n",
      "+----------+----------+----------+----------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Low'] == 181.850006).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby and Aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_info = 'sales_info.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('agga').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(sales_info, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|     FB|   Carl|870.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "+-------+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
